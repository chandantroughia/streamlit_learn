{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579631b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_visual_qa.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_visual_qa.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(page_title=\"Visual QA Bot\", page_icon=\"üñºÔ∏è\")\n",
    "\n",
    "# Title\n",
    "st.title(\"üñºÔ∏è Visual QA Bot\")\n",
    "st.markdown(\"Upload an image and ask questions about it\")\n",
    "\n",
    "# Initialize chat history\n",
    "msg_history = StreamlitChatMessageHistory(key=\"chat_messages\")\n",
    "\n",
    "# Initialize session state for image\n",
    "if \"uploaded_image\" not in st.session_state:\n",
    "    st.session_state.uploaded_image = None\n",
    "\n",
    "# Function to encode image\n",
    "def encode_image(image):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "# Store uploaded image\n",
    "if uploaded_file:\n",
    "    st.session_state.uploaded_image = Image.open(uploaded_file)\n",
    "    st.image(st.session_state.uploaded_image, caption=\"Uploaded Image\", use_container_width=True)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Display chat history (always visible)\n",
    "for msg in msg_history.messages:\n",
    "    with st.chat_message(\"user\" if isinstance(msg, HumanMessage) else \"assistant\"):\n",
    "        st.markdown(msg.content)\n",
    "\n",
    "# Chat input (always visible)\n",
    "if prompt := st.chat_input(\"Ask anything about the image...\"):\n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    msg_history.add_user_message(prompt)\n",
    "    \n",
    "    # Generate response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            try:\n",
    "                if st.session_state.uploaded_image:\n",
    "                    # With image\n",
    "                    img_base64 = encode_image(st.session_state.uploaded_image)\n",
    "                    \n",
    "                    message = HumanMessage(\n",
    "                        content=[\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{img_base64}\"}\n",
    "                        ]\n",
    "                    )\n",
    "                    response = llm.invoke([message])\n",
    "                else:\n",
    "                    # Without image - just text\n",
    "                    st.warning(\"‚ö†Ô∏è No image uploaded. Please upload an image to ask visual questions!\")\n",
    "                    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                \n",
    "                st.markdown(response.content)\n",
    "                msg_history.add_ai_message(response.content)\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error: {str(e)}\")\n",
    "\n",
    "# Sidebar with clear button\n",
    "with st.sidebar:\n",
    "    if st.button(\"üóëÔ∏è Clear Chat\"):\n",
    "        msg_history.clear()\n",
    "        st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a5f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
